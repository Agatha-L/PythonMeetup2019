{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img  style=\"float: left; padding-right: 100px; width: 350px\" src=\"images/logo.png\">\n",
    "    </div>\n",
    "    <h2 align=\"center\">PYTHON CONFERENCE TANZANIA 2019</h2>\n",
    "<hr>\n",
    "<h4 align=\"center\">Zephania Reuben</h4>\n",
    "<h4 align=\"center\">December 10, 2019</h4>\n",
    "<hr>\n",
    "<h2 align=\"center\">scikit-learn</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>OUTLINES</u>\n",
    "- Introduction to Scikit-Learn\n",
    " - Basic Scikit-Learn Concepts\n",
    " - Scikit-Learn Design\n",
    "- Linear Models with Scikit-Learn\n",
    " - Linear Regression\n",
    " - Logistic Regression\n",
    "- Validation and Model Fine Tuning\n",
    " - Validation\n",
    " - Model Fine Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Introduction\n",
    "#### 1.1.Scikit-Learn\n",
    "Scikit-Learn is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms.\n",
    "- It provides many unsupervised learning algorithms.It's built upon some of the technologies such as :\n",
    " - NumPy\n",
    " - pandas and\n",
    " - Matplotlib\n",
    "- It is also used for data wrangling and data analysis.\n",
    "\n",
    "#### 1.2.Scikit-learn design\n",
    "Scikit-Learn library is organized in three fundamental APIs(Interfaces):\n",
    " - Estimator\n",
    " - Predictor\n",
    " - Transformer\n",
    " \n",
    "**Estimator:** This is the core interface of Scikit-Learn, estimator objects are used to perform estimation of some parameters based on dataset. All learning algorithms, whether supervised or unsupervised, classification,regression, or clustering, implement the Estimator interface and expose a **fit()** method.The **fit()** method takes the dataset also sometimes labels for supervised learning and in this way estimator \"learns\" how to make predictions on unseen data for supervised learning. For instance an imputer object in the example below is an estimator.\n",
    "\n",
    "``Example``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mport libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read the dataset\n",
    "dataset = pd.read_csv('Data/Titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check null values \n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into features and labels\n",
    "features,labels = train_test_split(dataset) \n",
    "#select an Age column\n",
    "age_column = features['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the data\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "age_column_fitted = imputer.fit(np.array(age_column).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.9486692])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_column_fitted.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.94866920152091"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find median using numpy\n",
    "mean_age = np.mean(age_column)\n",
    "mean_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Transformer:** Transformer extends **estimator class** and transformer objects they can also transform a dataset. Transformation is performed by the method **transform()** which passes the dataset as it's parameter. It returns the transformed dataset.\n",
    "Transformation is done based on the learned parameters, also a method **fit_transform()** can be used to perform both fit and transformation.\n",
    "\n",
    "``Example :``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the age column by filling the null value \n",
    "age_column = age_column_fitted.transform(np.array(age_column).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the resulting array to pandas dataframe\n",
    "age_dataframe = pd.DataFrame(data=age_column,columns=['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null value # the dataset have been transformed \n",
    "age_dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictor:** Also predictor class extends the estimator interface, and for a given model to \"work\" it must implement (and expose) a **predict()** method.Estimators are capable of making predictions given dataset. For example the LinearRegression model is a predictor. Predict method takes a dataset of new instance and returns a dataset corresponding to predictions. Also has score method to measure the quality of predictions given a test set.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "#read the dataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegressor\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "#split dataset into features and labels\n",
    "fitted = imputer.fit(features)\n",
    "features = fitted.transform(features)\n",
    "#or\n",
    "dataset = imputer.fit_transform(features)\n",
    "linearRegression = LinearRegressor(features,labels)\n",
    "linearRegression.fit()\n",
    "#use testset to find predictions\n",
    "predictions = linearRegression.predict(test_features)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Models With Scikit-Learn\n",
    "#### 2.1 Linear Regression\n",
    "   This is model which is made up of simple linear function, and it is very easy to visualize.Now we will start with some basic modeling with linear regression. Traditional linear regression is the first, and therefore, probably the most fundamental model a straight line through data. A mathematical expression for linear regression is as follows:\n",
    "<p>$$y = a + bx$$</p>   \n",
    "\n",
    "``Example``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Load the Boston dataset from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "#load dataset\n",
    "dataset = datasets.load_boston()\n",
    "#split to target and label\n",
    "features, label = dataset.data,dataset.target\n",
    "#split into train set and test set\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,label)\n",
    "#create a linear regression model\n",
    "linear = LinearRegression()\n",
    "#fit the model(train the model)\n",
    "linear.fit(X_train,y_train)\n",
    "#let's get predictions\n",
    "predictions = linear.predict(X_test)\n",
    "print(\"Actual values: \",y_test[10:15])\n",
    "print(\"Predicted : \",predictions[10:15])\n",
    "print(\"Model score : \",linear.score(X_test,y_test))\n",
    "print(\"Coefficients : \",linear.coef_)\n",
    "print(\"Intercept : \",linear.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Logistic Regression\n",
    " It allows us to predict probability that an observation is of a certain class. It is been called regression but it is classification algorithm.It combines the linear equation and logit/sigmoid or logistic function:\n",
    " \n",
    " $$z = a + bx$$ \n",
    " $$y = \\frac{1}{e^{-(a+bx)}}$$\n",
    "\n",
    "``Example``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:  0.9736842105263158\n",
      "Actual values:  [2 0 1 2 0]\n",
      "Predicted :  [2 0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#load dataset for classification\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "#split the dataset into traing and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,target)\n",
    "#create a linear regression model\n",
    "logistic = LogisticRegression(multi_class='auto')\n",
    "#fit the model(train the model)\n",
    "logistic.fit(X_train,y_train)\n",
    "#let's get predictions\n",
    "predictions = logistic.predict(X_test)\n",
    "print('Model accuracy: ',logistic.score(X_test,y_test))\n",
    "print(\"Actual values: \",y_test[10:15])\n",
    "print(\"Predicted : \",predictions[10:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Validation and Model Fine Tuning\n",
    "### 3.1. Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different accuracies :  [1.         0.8        1.         0.93333333 1.         0.93333333\n",
      " 1.         0.93333333 1.         0.86666667] \n",
      "\n",
      "Actual values:  [2 2 2 1 2]\n",
      "Predicted :  [2 0 1 2 0]\n",
      "0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#load dataset for classification\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "#split the dataset into traing and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,target)\n",
    "#create a linear regression model\n",
    "logistic = LogisticRegression(multi_class='auto')\n",
    "#fit the model(train the model)\n",
    "logistic.fit(X_train,y_train)\n",
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# Conduct k-fold cross-validation\n",
    "cv_results = cross_val_score(logistic, # Pipeline\n",
    "features, # Feature matrix\n",
    "target, # Target vector\n",
    "cv=kf, # Cross-validation technique\n",
    "scoring=\"accuracy\", # Loss function\n",
    "n_jobs=-1) # Use all CPU scores\n",
    "#check the mean accuracy\n",
    "print(\"Different accuracies : \",cv_results,\"\\n\")\n",
    "print(\"Actual values: \",y_test[10:15])\n",
    "print(\"Predicted : \",predictions[10:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Model Tuning \n",
    "   This is often referred to as hyperparameter tuning, hyperparameter optimization, or model selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries \n",
    "import numpy as np \n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "# Create logistic regressio\n",
    "logistic = linear_model.LogisticRegression()\n",
    "# Create range of candidate penalty hyperparameter \n",
    "penalty = ['l1', 'l2']\n",
    "# Create range of candidate regularization hyperparameter values\n",
    "C = np.logspace(0, 4, 10)\n",
    "# Create dictionary hyperparameter candidates \n",
    "parameters = dict(C=C, penalty=penalty)\n",
    "# Create grid search\n",
    "gridsearch = GridSearchCV(logistic,parameters)\n",
    "# Fit grid search\n",
    "best_model = gridsearch.fit(features, target)\n",
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<img style=\"float: right; padding-right: 100px; width: 100%\" src=\"images/final.png\">\n",
    "<img style=\"float: right; padding-right: 100px; width: 100%\" src=\"images/python.png\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
